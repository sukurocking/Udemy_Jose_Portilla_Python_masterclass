{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1c884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daac01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903c6c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cee570",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"sales\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf5fec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561040f",
   "metadata": {},
   "source": [
    "#### In this exercise, we will try to reduce overfitting by introducing a penalty term, which is done by Ridge regression\n",
    "Also called L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6cba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738d00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_converter = PolynomialFeatures(degree=3, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e584eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = poly_converter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7633ab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02823655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1db809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee8a4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.93200000e+02, 1.84000000e+01, 6.57000000e+01, 3.73262400e+04,\n",
       "       3.55488000e+03, 1.26932400e+04, 3.38560000e+02, 1.20888000e+03,\n",
       "       4.31649000e+03, 7.21142957e+06, 6.86802816e+05, 2.45233397e+06,\n",
       "       6.54097920e+04, 2.33555616e+05, 8.33945868e+05, 6.22950400e+03,\n",
       "       2.22433920e+04, 7.94234160e+04, 2.83593393e+05])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "998e4fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.47000000e+01, 4.94000000e+01, 4.57000000e+01, 5.58009000e+03,\n",
       "       3.69018000e+03, 3.41379000e+03, 2.44036000e+03, 2.25758000e+03,\n",
       "       2.08849000e+03, 4.16832723e+05, 2.75656446e+05, 2.55010113e+05,\n",
       "       1.82294892e+05, 1.68641226e+05, 1.56010203e+05, 1.20553784e+05,\n",
       "       1.11524452e+05, 1.03171406e+05, 9.54439930e+04])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec384048",
   "metadata": {},
   "source": [
    "We need to apply feature scaling on the *X_train* and *X_test* datasets independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07e91873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d7ee782",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1692f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._data.StandardScaler"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7191019",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32bde175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "853e3b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49300171, -0.33994238,  1.61586707,  0.28407363, -0.02568776,\n",
       "        1.49677566, -0.59023161,  0.41659155,  1.6137853 ,  0.08057172,\n",
       "       -0.05392229,  1.01524393, -0.36986163,  0.52457967,  1.48737034,\n",
       "       -0.66096022, -0.16360242,  0.54694754,  1.37075536])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9a23f",
   "metadata": {},
   "source": [
    "In the above, the values are standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bcdaa",
   "metadata": {},
   "source": [
    "#### Now we will apply Ridge regression or L2 regularization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e554d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc0c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07d9a850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20400411",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a21c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing error terms - MAE, RMSE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "MAE = mean_absolute_error(y_test, test_predictions)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8e4e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5774404204714181\n",
      "RMSE: 0.8946386461319672\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02763e8",
   "metadata": {},
   "source": [
    "#### Now we will use cross validation to perform the ridge regression model\n",
    "We will put aside *X_test* (which would be our hold-out test dataset) for now and use *X_train* as training-cum-validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62ad6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the error metrics to be used\n",
    "from sklearn.metrics import SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ff006c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "129abe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5b0f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default cv=None, which means leave-one-out cross validation\n",
    "#By default scoring=None, which means mean absolute error scoring is used\n",
    "ridge_cv_model = RidgeCV(alphas=(0.05, 0.1, 1.0, 10.0), scoring='neg_mean_squared_error', cv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5442688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([ 0.05,  0.1 ,  1.  , 10.  ]),\n",
       "        scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a14b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = ridge_cv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "549131de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing error terms - MAE, RMSE - This is to be used only for reporting and NOT fine tuning our model\n",
    "# y_test is our hold-out test dataset\n",
    "MAE = mean_absolute_error(y_test, test_predictions)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "264d6f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.4108099689476472\n",
      "RMSE: 0.5982211275186771\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {MAE}\")\n",
    "print(f\"RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be1fe039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa67179",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ff2c0",
   "metadata": {},
   "source": [
    "## LASSO regression or L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d60a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11614718",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_model = LassoCV(eps=0.001, n_alphas=100, max_iter=1000, cv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0008907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukumarsubudhi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+00, tolerance: 3.684e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoCV()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec106cc",
   "metadata": {},
   "source": [
    "There are 2 ways of overcoming the convergence warning. \n",
    "- Increasing max_iter above 1000 (which is the default value)\n",
    "- Increasing the eps value (which is the ratio of alpha_min and alpha_max). This way, the number of iterations is limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e2010",
   "metadata": {},
   "source": [
    "Below is the first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "702658c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_model = LassoCV(eps=0.001, n_alphas=100, cv=None, max_iter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eff044c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(max_iter=1000000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e6bf5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = lasso_cv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f7151f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.86023329,  0.12544598,  0.20746872, -4.99250395,  4.38026519,\n",
       "       -0.22977201, -0.        ,  0.07267717, -0.        ,  1.77780246,\n",
       "       -0.69614918, -0.        ,  0.12044132, -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1670a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43350346185900707\n"
     ]
    }
   ],
   "source": [
    "MAE = mean_absolute_error(y_test, test_predictions)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cfa66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6063140748984027\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03032e96",
   "metadata": {},
   "source": [
    "Using the 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a7a6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_model = LassoCV(eps=0.1, n_alphas=100, cv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ee42cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(eps=0.1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fa3660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = lasso_cv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "993c7a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.002651  , 0.        , 0.        , 0.        , 3.79745279,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b20a2810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6541723161252854\n"
     ]
    }
   ],
   "source": [
    "MAE = mean_absolute_error(y_test, test_predictions)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "545c1d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1308001022762533\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a7207",
   "metadata": {},
   "source": [
    "Considering the complexity of the model, the lasso regression model has performed quite good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520dc3c",
   "metadata": {},
   "source": [
    "## Elastic Net regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52922e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfc3391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_cv_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], eps=0.001, n_alphas=100, cv=None, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c363685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukumarsubudhi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+00, tolerance: 3.684e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the elastic model\n",
    "elastic_net_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06919167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increasing the max_iter parameter\n",
    "# The list of l1_ratios is given to be skewed towards 1\n",
    "elastic_net_cv_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], eps=0.001, n_alphas=100, cv=None, max_iter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53a40a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=1000000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, we considered training and validation data within the dataset X_train\n",
    "# X_test is the hold-out test dataset. This is the same pattern we followed earlier while performing Ridge regression and Lasso regression \n",
    "elastic_net_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "416d26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = elastic_net_cv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8563457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]\n"
     ]
    }
   ],
   "source": [
    "print(elastic_net_cv_model.l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b9f3969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is a hyperparameter\n",
    "elastic_net_cv_model.l1_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566a892",
   "metadata": {},
   "source": [
    "As we can see above, the model is disregarding Ridge regression and is only considering Lasso.\n",
    "Below you will see that the coefficients are the same as of Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a4cf838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.86023329,  0.12544598,  0.20746872, -4.99250395,  4.38026519,\n",
       "       -0.22977201, -0.        ,  0.07267717, -0.        ,  1.77780246,\n",
       "       -0.69614918, -0.        ,  0.12044132, -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_net_cv_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e969a7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004943070909225827"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_net_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8523932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the error metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5e90cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c3f3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8629470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43350346185900707\n",
      "0.6063140748984027\n"
     ]
    }
   ],
   "source": [
    "print(MAE)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96f205",
   "metadata": {},
   "source": [
    "##### Actually in most cases, it makes sense to directly go into elastic net cross validation modelling and compute the error metrics, rather than going individually into ridge or lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635009b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
